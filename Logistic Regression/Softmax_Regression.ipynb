{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPS17Kts6G3cAelBKKmkX3v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdityaMohanty374/ML_Algos/blob/main/Softmax_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sklearn model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('iris_synthetic_data_Softmax.csv')\n",
        "\n",
        "len_sep = df['sepal length'].tolist()\n",
        "wid_sep = df['sepal width'].tolist()\n",
        "len_pet = df['petal length'].tolist()\n",
        "wid_pet = df['petal width'].tolist()\n",
        "label = df['label'].tolist()"
      ],
      "metadata": {
        "id": "tO1qbrkJYKiA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT92NbpwK5DM",
        "outputId": "8e965c23-0eb8-417a-8653-852ee0dff9ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
        "X = df[['sepal length', 'sepal width', 'petal length', 'petal width']]\n",
        "y = np.array(label)\n",
        "model.fit(X, y.flatten())\n",
        "pred = model.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfUuNG4lZpIv",
        "outputId": "077b45fb-5552-42c5-8aae-7be2c07ddf17"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 3, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sklearn Softmax Accuracy:\", accuracy_score(y.flatten(), pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovIgvw2LaCmz",
        "outputId": "9e1b41ab-2bd4-4eee-b65e-508be1bd3c4b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sklearn Softmax Accuracy: 0.9933333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Custom Model\n",
        "alpha = 0.01\n",
        "x = [None for _ in range(4)]\n",
        "W = [[np.random.randn() for _ in range(4)] for _ in range(3)] #3 classes x 4 features\n",
        "b = [0.0 for _ in range(3)]\n",
        "def softmax(z):\n",
        "    exp_z = [np.exp(i) for i in z]\n",
        "    sum_exp = sum(exp_z)\n",
        "    return [i / sum_exp for i in exp_z]\n",
        "\n",
        "def one_hot(y_i, num_classes):\n",
        "    return [1 if i == y_i else 0 for i in range(num_classes)]\n",
        "\n",
        "for epoch in range(300):\n",
        "  total_loss = 0\n",
        "  for j in range(len(label)):\n",
        "    x[0] = len_sep[j]\n",
        "    x[1] = wid_sep[j]\n",
        "    x[2] = len_pet[j]\n",
        "    x[3] = wid_pet[j]\n",
        "    X = x\n",
        "    y = label[j]\n",
        "    target = one_hot(y, 4)\n",
        "    logits = [b[i] + sum(x[k] * W[k][i] for k in range(4)) for i in range(3)]\n",
        "    probs = softmax(logits)\n",
        "    # Cross-entropy loss\n",
        "    loss = -sum(target[j] * np.log(probs[j] + 1e-8) for j in range(3)) # 3 classes\n",
        "    total_loss += loss\n",
        "    # Gradient and update\n",
        "    for i in range(3): # 3 classes\n",
        "      for k in range(4): #4 features\n",
        "        grad = (probs[i] - target[i]) * x[k]\n",
        "        W[k][i] -= alpha * grad\n",
        "      b[i] -= alpha * (probs[i] - target[i])\n",
        "\n",
        "    if epoch % 299 == 0:\n",
        "        print(f\"Epoch {epoch}: Loss = {total_loss/len(label):.4f}\")\n",
        "# Prediction\n",
        "predictions = []\n",
        "for xi in X:\n",
        "    z = [sum(W[k][j] * xi[j] for j in range(4)) + b[k] for k in range(3)]\n",
        "    probs = softmax(z)\n",
        "    pred_class = probs.index(max(probs))  # argmax\n",
        "    predictions.append(pred_class)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = np.mean([pred == true for pred, true in zip(predictions, y)])\n",
        "print(\"Training Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "yZKPsZ1GaF46",
        "outputId": "d55258c6-6ad4-4435-fd06-3dd2998f1e1f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-654798100.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Cross-entropy loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-654798100.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Cross-entropy loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-654798100.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Cross-entropy loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load data\n",
        "data = pd.read_csv('iris_synthetic_data_Softmax.csv')\n",
        "len_sep = data['sepal length'].tolist()\n",
        "wid_sep = data['sepal width'].tolist()\n",
        "len_pet = data['petal length'].tolist()\n",
        "wid_pet = data['petal width'].tolist()\n",
        "label = data['target'].tolist()\n",
        "\n",
        "# Initialize parameters\n",
        "alpha = 0.01\n",
        "W = [[np.random.randn() for _ in range(4)] for _ in range(3)]  # 3 classes x 4 features\n",
        "b = [0.0 for _ in range(3)]\n",
        "\n",
        "def softmax(z):\n",
        "    exp_z = [np.exp(i) for i in z]\n",
        "    sum_exp = sum(exp_z)\n",
        "    return [i / sum_exp for i in exp_z]\n",
        "\n",
        "def one_hot(y_i, num_classes):\n",
        "    return [1 if i == y_i else 0 for i in range(num_classes)]\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(300):\n",
        "    total_loss = 0\n",
        "    for j in range(len(label)):\n",
        "        x = [len_sep[j], wid_sep[j], len_pet[j], wid_pet[j]]\n",
        "        y = label[j]\n",
        "        target = one_hot(y, 3)  # Only 3 classes (0, 1, 2)\n",
        "        logits = [b[i] + sum(x[k] * W[i][k] for k in range(4)) for i in range(3)]\n",
        "        probs = softmax(logits)\n",
        "        loss = -sum(target[j] * np.log(probs[j] + 1e-8) for j in range(3))\n",
        "        total_loss += loss\n",
        "        # Gradient update\n",
        "        for i in range(3):\n",
        "            for k in range(4):\n",
        "                grad = (probs[i] - target[i]) * x[k]\n",
        "                W[i][k] -= alpha * grad\n",
        "            b[i] -= alpha * (probs[i] - target[i])\n",
        "    if epoch % 50 == 0 or epoch == 299:\n",
        "        print(f\"Epoch {epoch}: Loss = {total_loss/len(label):.4f}\")\n",
        "\n",
        "# Prediction\n",
        "predictions = []\n",
        "for j in range(len(label)):\n",
        "    xi = [len_sep[j], wid_sep[j], len_pet[j], wid_pet[j]]\n",
        "    z = [sum(W[i][k] * xi[k] for k in range(4)) + b[i] for i in range(3)]\n",
        "    probs = softmax(z)\n",
        "    pred_class = probs.index(max(probs))\n",
        "    predictions.append(pred_class)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = np.mean([pred == true for pred, true in zip(predictions, label)])\n",
        "print(\"Training Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "pwOr9JZFfYUQ",
        "outputId": "f68673dd-4f43-4631-c48d-fa4f38c99186"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'target'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'target'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3189851408.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlen_pet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'petal length'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mwid_pet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'petal width'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Initialize parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'target'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"iris_synthetic_data_Softmax.csv\")\n",
        "\n",
        "# Clean data\n",
        "df = df[['sepal length', 'sepal width', 'petal length', 'petal width', 'label']]\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Extract features and labels\n",
        "len_sep = df['sepal length'].tolist()\n",
        "wid_sep = df['sepal width'].tolist()\n",
        "len_pet = df['petal length'].tolist()\n",
        "wid_pet = df['petal width'].tolist()\n",
        "label = df['label'].astype(int).tolist()  # ensure labels are integers\n",
        "\n",
        "# Hyperparameters\n",
        "alpha = 0.01\n",
        "num_classes = 4\n",
        "num_features = 4\n",
        "\n",
        "# Initialize weights and bias\n",
        "W = [[np.random.randn() for _ in range(num_features)] for _ in range(num_classes)]\n",
        "b = [0.0 for _ in range(num_classes)]\n",
        "\n",
        "# Helper functions\n",
        "def softmax(z):\n",
        "    exp_z = [np.exp(i) for i in z]\n",
        "    sum_exp = sum(exp_z)\n",
        "    return [i / sum_exp for i in exp_z]\n",
        "\n",
        "def one_hot(y_i, num_classes):\n",
        "    return [1 if i == y_i else 0 for i in range(num_classes)]\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(300):\n",
        "    total_loss = 0\n",
        "    for j in range(len(label)):\n",
        "        x = [len_sep[j], wid_sep[j], len_pet[j], wid_pet[j]]\n",
        "        y = label[j]\n",
        "        target = one_hot(y, num_classes)\n",
        "\n",
        "        logits = [b[i] + sum(x[k] * W[i][k] for k in range(num_features)) for i in range(num_classes)]\n",
        "        probs = softmax(logits)\n",
        "\n",
        "        # Cross-entropy loss\n",
        "        loss = -sum(target[j] * np.log(probs[j] + 1e-8) for j in range(num_classes))\n",
        "        total_loss += loss\n",
        "\n",
        "        # Gradient descent update\n",
        "        for i in range(num_classes):\n",
        "            for k in range(num_features):\n",
        "                grad = (probs[i] - target[i]) * x[k]\n",
        "                W[i][k] -= alpha * grad\n",
        "            b[i] -= alpha * (probs[i] - target[i])\n",
        "\n",
        "    if epoch % 50 == 0 or epoch == 299:\n",
        "        print(f\"Epoch {epoch} - Loss: {total_loss / len(label):.4f}\")\n",
        "\n",
        "# Prediction\n",
        "predictions = []\n",
        "for j in range(len(label)):\n",
        "    x = [len_sep[j], wid_sep[j], len_pet[j], wid_pet[j]]\n",
        "    z = [sum(W[i][k] * x[k] for k in range(num_features)) + b[i] for i in range(num_classes)]\n",
        "    probs = softmax(z)\n",
        "    pred_class = probs.index(max(probs))\n",
        "    predictions.append(pred_class)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = np.mean([pred == true for pred, true in zip(predictions, label)])\n",
        "print(\"Training Accuracy:\", accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH1yieqAtg70",
        "outputId": "f5a40656-3298-4aa8-faab-14503bd0c261"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 - Loss: 0.0974\n",
            "Epoch 50 - Loss: 0.0098\n",
            "Epoch 100 - Loss: 0.0076\n",
            "Epoch 150 - Loss: 0.0071\n",
            "Epoch 200 - Loss: 0.0068\n",
            "Epoch 250 - Loss: 0.0066\n",
            "Epoch 299 - Loss: 0.0065\n",
            "Training Accuracy: 0.934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5mAcB9qDuIIC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
